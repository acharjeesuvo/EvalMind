# EvalMind
A Streamlit-based annotation and review platform for evaluating LLM-generated reasoning on multimodal data using human-in-the-loop feedback across dimensions like Evidence Recognition, Reasoning Chain, and Text Naturalness.

# LLM Reasoning Review Tool

A web-based annotation and review system built with Streamlit for assessing large language model (LLM) reasoning over image and text data. Users rate generated outputs across three dimensions and provide feedback via an intuitive UI. Reviewers can audit contributor decisions and ensure data quality through a dashboard and quality control interface.

## Features
- Multi-user annotation for image-text pairs with LLM reasoning
- Evaluation across Evidence Recognition, Reasoning Chain, and Text Naturalness
- Accept/Reject verdicts and reviewer quality control
- Contributor performance dashboard and progress tracking

## Technologies
- Python
- Streamlit
- Pandas
- Excel-based storage (can be extended to SQL/NoSQL backends)
